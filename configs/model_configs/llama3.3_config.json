{
    "model_info": {
        "provider": "llama3",
        "name": "/path/to/Llama-3.3-70B-Instruct"
    },
    "api_key_info": {
        "api_keys": [
            ""
        ],
        "api_key_use": 0
    },
    "params": {
        "temperature": 0.1,
        "seed": 100,
        "gpus": [],
        "device": "cuda",
        "max_output_tokens": 128,
        "ft_path": "",
        "decoding_method": "greedy"
    }
}