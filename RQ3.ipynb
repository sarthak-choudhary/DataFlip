{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ3: Fine-tuned vs Base FNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import OpenPromptInjection as PI\n",
    "from OpenPromptInjection.utils import open_config\n",
    "from OpenPromptInjection import DataSentinelDetector\n",
    "from OpenPromptInjection.evaluator.utils import *\n",
    "from OpenPromptInjection.evaluator.gleu_utils import *\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Literal\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection Models\n",
    "Set `detector_path_config` to load the detection model. In this case, setting `ft_path=\"\"`just loads the base Mistral model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba351f4e7a454ee598de5bbcc0de354e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7591644753d0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/nobackup3/divyam/envs/open-prompt-injection/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "detector_config_path = 'configs/model_configs/mistral_config.json'\n",
    "detector_config = open_config(detector_config_path)\n",
    "detector_config[\"params\"][\"gpus\"] = ['0', '1', '2', '3']\n",
    "# Load the DataSentinel finetuned detector.\n",
    "detector_ft = DataSentinelDetector(detector_config)\n",
    "\n",
    "detector_config[\"params\"][\"ft_path\"] = \"\"\n",
    "# Load the base Mistral model.\n",
    "detector_base = DataSentinelDetector(detector_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_task_configs = [\n",
    "    \"gigaword_config.json\",\n",
    "    \"hsol_config.json\",\n",
    "    \"jfleg_config.json\",\n",
    "    \"mrpc_config.json\",\n",
    "    \"rte_config.json\",\n",
    "    \"sms_spam_config.json\",\n",
    "    \"sst2_config.json\"\n",
    "]\n",
    "\n",
    "inject_task_configs = [\n",
    "    # \"websiteinject_config.json\",\n",
    "    \"gigaword_config.json\",\n",
    "    \"hsol_config.json\",\n",
    "    \"jfleg_config.json\",\n",
    "    \"mrpc_config.json\",\n",
    "    \"rte_config.json\",\n",
    "    \"sms_spam_config.json\",\n",
    "    \"sst2_config.json\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benign FPR\n",
    "Get FPR on benign samples. We only consider the target task here, without any prompt injection. We store the detection rate and detector responses under `results`.\n",
    "\n",
    "`results` structure:\n",
    "```\n",
    "results\n",
    "    |__ target_task (e.g. summarization)\n",
    "            |__ det_base (Baseline detection LLM)\n",
    "                    |__ det_rate (detection rate of the detection LLM)\n",
    "                    |__ responses (responses of the detection LLM)\n",
    "            |__ det_ft (Fine-tuned detection LLM)\n",
    "                    |__ det_rate (detection rate of the detection LLM)\n",
    "                    |__ responses (responses of the detection LLM)\n",
    "```\n",
    "\n",
    "1. `detected_benign_cnt_{base/ft}`: Benign samples detected as contaminated by the base or fine-tuned detection LLM.\n",
    "2. `detector_responses_benign_{base/ft}`: Responses of the base or fine-tuned detection LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results found at: ./results/RQ3/detector_benign_prompts.json!\n"
     ]
    }
   ],
   "source": [
    "results = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "\n",
    "save_path = \"./results/RQ3/detector_benign_prompts.json\"\n",
    "\n",
    "if os.path.exists(f\"{save_path}\"):\n",
    "    print(f\"Results found at: {save_path}!\")\n",
    "else:\n",
    "    for target_task_config in target_task_configs:\n",
    "        target_task = PI.create_task(open_config(config_path=f\"./configs/task_configs/{target_task_config}\"), 100)\n",
    "        \n",
    "        target_app = PI.create_app(target_task, None, defense='no')\n",
    "        \n",
    "        detected_benign_cnt_base = 0\n",
    "        detected_benign_cnt_ft = 0\n",
    "        detector_responses_benign_base = []\n",
    "        detector_responses_benign_ft = []\n",
    "        \n",
    "        # Run base detector on benign prompts\n",
    "        for i, (data_prompt, ground_truth_label) in enumerate(target_app):\n",
    "            benign = data_prompt\n",
    "            success_base, detector_response_base = detector_base.detect(benign)\n",
    "            detected_benign_cnt_base += success_base\n",
    "            detector_responses_benign_base.append(detector_response_base)\n",
    "\n",
    "        results[target_task.task][\"det_base\"][\"det_rate\"] = detected_benign_cnt_base\n",
    "        results[target_task.task][\"det_base\"][\"responses\"] = detector_responses_benign_base\n",
    "\n",
    "        # Run ft detector on benign prompts\n",
    "        for i, (data_prompt, ground_truth_label) in enumerate(target_app):\n",
    "            benign = data_prompt\n",
    "            success_ft, detector_response_ft = detector_ft.detect(benign)\n",
    "            detected_benign_cnt_ft += success_ft\n",
    "            detector_responses_benign_ft.append(detector_response_ft)\n",
    "\n",
    "        results[target_task.task][\"det_ft\"][\"det_rate\"] = detected_benign_cnt_ft\n",
    "        results[target_task.task][\"det_ft\"][\"responses\"] = detector_responses_benign_ft\n",
    "\n",
    "        with open(f\"{save_path}\", 'w') as fp:\n",
    "            json.dump(results, fp, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNR for Combined Attack\n",
    "Get FNR on samples crafted using the Combined Attack, for every combination of target and injected task. We store the detection rate and detector responses under `results`.\n",
    "\n",
    "`results` structure:\n",
    "```\n",
    "results\n",
    "    |__ inject_task (e.g. hate_detection)\n",
    "            |\n",
    "            target_task (e.g. summarization)\n",
    "                |__ det_base (Baseline detection LLM)\n",
    "                        |__ det_rate (detection rate of the detection LLM)\n",
    "                        |__ responses (responses of the detection LLM)\n",
    "                |__ det_ft (Fine-tuned detection LLM)\n",
    "                        |__ det_rate (detection rate of the detection LLM)\n",
    "                        |__ responses (responses of the detection LLM)\n",
    "```\n",
    "\n",
    "1. `detected_attack_prompt_cnt_{base/ft}`: Benign samples detected as contaminated by the base or fine-tuned detection LLM.\n",
    "2. `detector_responses_{base/ft}`: Responses of the base or fine-tuned detection LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results found at: ./results/RQ3/detector_combined_attack_prompts.json!\n"
     ]
    }
   ],
   "source": [
    "results = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "\n",
    "save_path = \"./results/RQ3/detector_combined_attack_prompts.json\"\n",
    "\n",
    "if os.path.exists(f\"{save_path}\"):\n",
    "    print(f\"Results found at: {save_path}!\")\n",
    "else:\n",
    "    for target_task_config in target_task_configs:\n",
    "        for inject_task_config in inject_task_configs:\n",
    "            if target_task_config==inject_task_config: continue\n",
    "            target_task = PI.create_task(open_config(config_path=f\"./configs/task_configs/{target_task_config}\"), 100)\n",
    "            inject_task = PI.create_task(open_config(config_path=f'configs/task_configs/{inject_task_config}'), 100, for_injection=True)\n",
    "            \n",
    "            attacker = PI.create_attacker('combine', inject_task)\n",
    "            \n",
    "            target_app = PI.create_app(target_task, None, defense='no')\n",
    "\n",
    "            detected_attack_prompt_cnt_base = 0\n",
    "            detected_attack_prompt_cnt_ft = 0\n",
    "            detector_responses_base = []\n",
    "            detector_responses_ft = []\n",
    "\n",
    "            # Run the base detector on combine attack prompts\n",
    "            for i, (data_prompt, ground_truth_label) in enumerate(target_app):\n",
    "                data_prompt_after_attack = attacker.inject(clean_data=data_prompt, idx=i, target_task=target_task.task)#, inject_task=inject_task.task)\n",
    "                success_base, detector_response_base = detector_base.detect(data_prompt_after_attack)\n",
    "                detected_attack_prompt_cnt_base += success_base\n",
    "                detector_responses_base.append(detector_response_base)\n",
    "\n",
    "            results[inject_task.task][target_task.task][\"det_base\"][\"det_rate\"] = detected_attack_prompt_cnt_base\n",
    "            results[inject_task.task][target_task.task][\"det_base\"][\"responses\"] = detector_responses_base\n",
    "\n",
    "            # Run the ft detector on combine attack prompts\n",
    "            for i, (data_prompt, ground_truth_label) in enumerate(target_app):\n",
    "                data_prompt_after_attack = attacker.inject(clean_data=data_prompt, idx=i, target_task=target_task.task)#, inject_task=inject_task.task)\n",
    "                success_ft, detector_response_ft = detector_ft.detect(data_prompt_after_attack)\n",
    "                detected_attack_prompt_cnt_ft += success_ft\n",
    "                detector_responses_ft.append(detector_response_ft)\n",
    "\n",
    "            results[inject_task.task][target_task.task][\"det_ft\"][\"det_rate\"] = detected_attack_prompt_cnt_ft\n",
    "            results[inject_task.task][target_task.task][\"det_ft\"][\"responses\"] = detector_responses_ft\n",
    "\n",
    "            with open(f\"{save_path}\", 'w') as fp:\n",
    "                json.dump(results, fp, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FNR for DataFlip\n",
    "Get FNR on samples crafted using DataFlip, for every combination of target and injected task. We store the detection rate and detector responses under `results`.\n",
    "\n",
    "`results` structure:\n",
    "```\n",
    "results\n",
    "    |__ inject_task (e.g. hate_detection)\n",
    "            |\n",
    "            target_task (e.g. summarization)\n",
    "                |__ det_base (Baseline detection LLM)\n",
    "                        |__ det_rate (detection rate of the detection LLM)\n",
    "                        |__ responses (responses of the detection LLM)\n",
    "                |__ det_ft (Fine-tuned detection LLM)\n",
    "                        |__ det_rate (detection rate of the detection LLM)\n",
    "                        |__ responses (responses of the detection LLM)\n",
    "```\n",
    "\n",
    "1. `detected_attack_prompt_cnt_{base/ft}`: Benign samples detected as contaminated by the base or fine-tuned detection LLM.\n",
    "2. `detector_responses_{base/ft}`: Responses of the base or fine-tuned detection LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results found at: ./results/RQ3/detector_dataflip_prompts.json!\n"
     ]
    }
   ],
   "source": [
    "results = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "\n",
    "save_path = \"./results/RQ3/detector_dataflip_prompts.json\"\n",
    "\n",
    "if os.path.exists(f\"{save_path}\"):\n",
    "    print(f\"Results found at: {save_path}!\")\n",
    "else:\n",
    "    for target_task_config in target_task_configs:\n",
    "        have_evaluated_benign = False\n",
    "        for inject_task_config in inject_task_configs:\n",
    "            if target_task_config==inject_task_config: continue\n",
    "            target_task = PI.create_task(open_config(config_path=f\"./configs/task_configs/{target_task_config}\"), 100)\n",
    "            inject_task = PI.create_task(open_config(config_path=f'configs/task_configs/{inject_task_config}'), 100, for_injection=True)\n",
    "            \n",
    "            attacker = PI.create_attacker('dataflip_datasentinel', inject_task)\n",
    "            \n",
    "            target_app = PI.create_app(target_task, None, defense='no')\n",
    "\n",
    "            detected_attack_prompt_cnt_base = 0\n",
    "            detected_attack_prompt_cnt_ft = 0\n",
    "            detector_responses_base = []\n",
    "            detector_responses_ft = []\n",
    "\n",
    "            # Run the base detector on dataflip attack prompts\n",
    "            for i, (data_prompt, ground_truth_label) in enumerate(target_app):\n",
    "                data_prompt_after_attack = attacker.inject(data_prompt=data_prompt, idx=i, target_task=target_task.task, inject_task=inject_task.task)\n",
    "                success_base, detector_response_base = detector_base.detect(data_prompt_after_attack)\n",
    "                detected_attack_prompt_cnt_base += success_base\n",
    "                detector_responses_base.append(detector_response_base)\n",
    "\n",
    "            results[inject_task.task][target_task.task][\"det_base\"][\"det_rate\"] = detected_attack_prompt_cnt_base\n",
    "            results[inject_task.task][target_task.task][\"det_base\"][\"responses\"] = detector_responses_base\n",
    "\n",
    "            # Run the ft detector on dataflip attack prompts\n",
    "            for i, (data_prompt, ground_truth_label) in enumerate(target_app):\n",
    "                data_prompt_after_attack = attacker.inject(data_prompt=data_prompt, idx=i, target_task=target_task.task, inject_task=inject_task.task)\n",
    "                success_ft, detector_response_ft = detector_ft.detect(data_prompt_after_attack)\n",
    "                detected_attack_prompt_cnt_ft += success_ft\n",
    "                detector_responses_ft.append(detector_response_ft)\n",
    "\n",
    "            results[inject_task.task][target_task.task][\"det_ft\"][\"det_rate\"] = detected_attack_prompt_cnt_ft\n",
    "            results[inject_task.task][target_task.task][\"det_ft\"][\"responses\"] = detector_responses_ft\n",
    "\n",
    "            with open(f\"{save_path}\", 'w') as fp:\n",
    "                json.dump(results, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(l):\n",
    "    return sum(l)/len(l)\n",
    "\n",
    "def printing_name(task_name):\n",
    "    words = task_name.split(\"_\")\n",
    "    return \" \".join(w[:1].upper() + w[1:] for w in words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_configs = [\n",
    "    \"gigaword_config.json\",\n",
    "    \"hsol_config.json\",\n",
    "    \"jfleg_config.json\",\n",
    "    \"mrpc_config.json\",\n",
    "    \"rte_config.json\",\n",
    "    \"sms_spam_config.json\",\n",
    "    \"sst2_config.json\"\n",
    "]\n",
    "\n",
    "task_configs = {\n",
    "    config: open_config(config_path=f\"./configs/task_configs/{config}\")\n",
    "    for config in task_configs\n",
    "}\n",
    "\n",
    "task_dataset_names = {\n",
    "    config[\"task_info\"][\"task\"]: config[\"dataset_info\"][\"dataset\"]\n",
    "    for config in task_configs.values()\n",
    "}\n",
    "\n",
    "task_name_map = {\n",
    "    k: printing_name(k)\n",
    "    for k in task_dataset_names.keys()\n",
    "}\n",
    "\n",
    "tasks = list(task_dataset_names.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "     \"benign\",\n",
    "     \"combined_attack\",\n",
    "     \"dataflip\",\n",
    "]\n",
    "\n",
    "all_results = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "def collect_results(name):\n",
    "    experiments_path = f\"results/RQ3/detector_{name}_prompts.json\"\n",
    "    \n",
    "    def load_results(path):\n",
    "        with open(experiments_path) as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    results = load_results(experiments_path)\n",
    "    for injected_task_name in tasks:\n",
    "        values_base = []\n",
    "        values_ft = []\n",
    "        for target_task_name in tasks:\n",
    "            if injected_task_name == target_task_name:\n",
    "                continue\n",
    "            if name==\"benign\":\n",
    "                values_base.append(results[injected_task_name][\"det_base\"][\"det_rate\"])\n",
    "                values_ft.append(results[injected_task_name][\"det_ft\"][\"det_rate\"])    \n",
    "            else:\n",
    "                values_base.append(results[injected_task_name][target_task_name][\"det_base\"][\"det_rate\"])\n",
    "                values_ft.append(results[injected_task_name][target_task_name][\"det_ft\"][\"det_rate\"])\n",
    "        all_results[name][injected_task_name][\"base\"] = mean(values_base) \n",
    "        all_results[name][injected_task_name][\"ft\"] = mean(values_ft) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    collect_results(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for the Base Mistral model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Mistral 7B (Base)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Injected Task</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR Combined Attack</th>\n",
       "      <th>FNR DataFlip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate Detection</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grammar Correction</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Duplicate Sentence Detection</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natural Language Inference</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spam Detection</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentiment Analysis</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Injected Task    FPR FNR Combined Attack FNR DataFlip\n",
       "0                 Summarization   92.0                 1.5          7.0\n",
       "1                Hate Detection   82.0                 1.5         10.0\n",
       "2            Grammar Correction   81.0                 0.8          4.5\n",
       "3  Duplicate Sentence Detection  100.0                 1.3         11.7\n",
       "4    Natural Language Inference   97.0                 1.5          8.5\n",
       "5                Spam Detection   79.0                 1.2          4.8\n",
       "6            Sentiment Analysis   85.0                 1.2         10.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Model: Mistral 7B (Base)\")\n",
    "data = {\n",
    "    \"Injected Task\": [task_name[1] for task_name in task_name_map.items()],\n",
    "        \"FPR\": [f\"{all_results['benign'][task]['base']:.1f}\" for task in task_name_map],\n",
    "    \"FNR Combined Attack\": [f\"{100-all_results['combined_attack'][task]['base']:.1f}\" for task in task_name_map],\n",
    "    \"FNR DataFlip\": [f\"{100-all_results['dataflip'][task]['base']:.1f}\" for task in task_name_map],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for the fine-tuned DataSentinel model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DataSentinel (FT)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Injected Task</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR Combined Attack</th>\n",
       "      <th>FNR DataFlip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hate Detection</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grammar Correction</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Duplicate Sentence Detection</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natural Language Inference</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spam Detection</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentiment Analysis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Injected Task  FPR FNR Combined Attack FNR DataFlip\n",
       "0                 Summarization  0.0                 0.0         46.5\n",
       "1                Hate Detection  0.0                 0.0         98.7\n",
       "2            Grammar Correction  0.0                 0.0         97.5\n",
       "3  Duplicate Sentence Detection  0.0                 0.0         88.2\n",
       "4    Natural Language Inference  0.0                 0.0         87.3\n",
       "5                Spam Detection  1.0                 0.0         95.0\n",
       "6            Sentiment Analysis  0.0                 0.0         93.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Model: DataSentinel (FT)\")\n",
    "data = {\n",
    "    \"Injected Task\": [task_name[1] for task_name in task_name_map.items()],\n",
    "        \"FPR\": [f\"{all_results['benign'][task]['ft']:.1f}\" for task in task_name_map],\n",
    "    \"FNR Combined Attack\": [f\"{100-all_results['combined_attack'][task]['ft']:.1f}\" for task in task_name_map],\n",
    "    \"FNR DataFlip\": [f\"{100-all_results['dataflip'][task]['ft']:.1f}\" for task in task_name_map],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-prompt-injection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
